{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3As4Gc0SsUb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\bnsla\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import nltk\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uZE-4qaZtPjN"
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"Data/train.txt\",header=None, sep=\";\", names=[\"Comment\", \"Emotion\"], encoding=\"utf-8\")\n",
    "df2 = pd.read_csv(\"Data/text_emotion_data_2.csv\")\n",
    "df3 = pd.read_csv(\"Data/emotion_dataset_2.csv\")\n",
    "df4 = pd.read_csv(\"Data/Emotion_classify_Data.csv\")\n",
    "df5 = pd.read_csv(\"Data/Emotion(angry).csv\")\n",
    "df6 = pd.read_csv(\"Data/Emotion(happy).csv\")\n",
    "df7 = pd.read_csv(\"Data/Emotion(sad).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5Fco9z1mtSY7"
   },
   "outputs": [],
   "source": [
    "df1 = df1.rename(columns = {\"Comment\":\"Text\"})\n",
    "df2 = df2.rename(columns = {\"content\":\"Text\",\"sentiment\":\"Emotion\"})\n",
    "df2 = df2[[\"Text\",\"Emotion\"]]\n",
    "df3 = df3[[\"Text\",\"Emotion\"]]\n",
    "df4 = df4.rename(columns = {\"Comment\":\"Text\"})\n",
    "df = pd.concat([df1,df2,df3,df4,df5,df6,df7])\n",
    "df = df.drop_duplicates()\n",
    "df[\"Emotion\"] = df[\"Emotion\"].replace({\"sadness\":\"sad\"})\n",
    "df[\"Emotion\"] = df[\"Emotion\"].replace({\"happiness\":\"joy\",\"fun\":\"joy\",\"relief\":\"joy\",\"enthusiasm\":\"joy\",\"happy\":\"joy\"})\n",
    "df[\"Emotion\"] = df[\"Emotion\"].replace({\"happiness\":\"joy\",\"fun\":\"joy\",\"relief\":\"joy\",\"enthusiasm\":\"joy\",\"happy\":\"joy\"})\n",
    "df[\"Emotion\"] = df[\"Emotion\"].replace({\"worry\":\"fear\"})\n",
    "df[\"Emotion\"] = df[\"Emotion\"].replace({\"hate\":\"anger\",\"disgust\":\"anger\",\"angry\":\"anger\"})\n",
    "df[\"Emotion\"] = df[\"Emotion\"].replace({\"empty\":\"neutral\",\"boredom\":\"neutral\",\"angry\":\"anger\"})\n",
    "df = df[df[\"Emotion\"].isin([\"joy\",\"sad\",\"fear\",\"neutral\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "s3YUfHw7t-nY"
   },
   "outputs": [],
   "source": [
    "df = df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T1GrSUl4umAP",
    "outputId": "efc06f68-1e8b-4feb-9e5f-a6b531d2c5bf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bnsla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the English stopwords\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "QA3QR3ZQt_mb"
   },
   "outputs": [],
   "source": [
    "def clean_text(docs):\n",
    "    # stopwords = nltk.corpus.stopwords.words(\"English\")\n",
    "    docs = docs.lower()\n",
    "    docs = re.sub(\"[^a-zA-Z]\", \" \", docs)\n",
    "    docs = docs.split()\n",
    "    stemmer = PorterStemmer()\n",
    "    words = []\n",
    "    for i in docs:\n",
    "        if i not in stopwords:\n",
    "            word = stemmer.stem(i)\n",
    "            words.append(word)\n",
    "    doc = \" \".join(words)\n",
    "    return doc\n",
    "\n",
    "def length(doc):\n",
    "    doclen = len(doc.split(\" \"))\n",
    "    return doclen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Ti1UbRPwuQHt"
   },
   "outputs": [],
   "source": [
    "df[\"cleaned_doc\"] = df[\"Text\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "n9ZBquA_uSpE"
   },
   "outputs": [],
   "source": [
    "df[\"length\"] = df[\"cleaned_doc\"].apply(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "XdNjy_m9vjwH"
   },
   "outputs": [],
   "source": [
    "df = df[df[\"length\"] != 1009]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "3LDHF3JuvxMd"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df[\"cleaned_doc\"],)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "input_vector = tokenizer.texts_to_sequences(df[\"cleaned_doc\"])\n",
    "input_vector = pad_sequences(sequences=input_vector, maxlen=300, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "FdjvignvwCca"
   },
   "outputs": [],
   "source": [
    "x_train = input_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "NCPdcSx5wD9b"
   },
   "outputs": [],
   "source": [
    "lb = LabelEncoder()\n",
    "y_train = lb.fit_transform(df[\"Emotion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "YB5YOcxU9U3h",
    "outputId": "03c6aa80-7d7b-4d0a-f9ac-db7534d4c0af"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>cleaned_doc</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sad</td>\n",
       "      <td>didnt feel humili</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sad</td>\n",
       "      <td>go feel hopeless damn hope around someon care ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ive been feeling a little burdened lately wasn...</td>\n",
       "      <td>sad</td>\n",
       "      <td>ive feel littl burden late wasnt sure</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i feel as confused about life as a teenager or...</td>\n",
       "      <td>fear</td>\n",
       "      <td>feel confus life teenag jade year old man</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i have been with petronas for years i feel tha...</td>\n",
       "      <td>joy</td>\n",
       "      <td>petrona year feel petrona perform well made hu...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67911</th>\n",
       "      <td>Stop crying over yesterday and start smiling f...</td>\n",
       "      <td>sad</td>\n",
       "      <td>stop cri yesterday start smile tomorrow</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67912</th>\n",
       "      <td>An Eye with Dust ‘n A Heart with Trust Always ...</td>\n",
       "      <td>sad</td>\n",
       "      <td>eye dust n heart trust alway cri</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67913</th>\n",
       "      <td>Tears come from the heart and not from the brain.</td>\n",
       "      <td>sad</td>\n",
       "      <td>tear come heart brain</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67914</th>\n",
       "      <td>Sometimes you have to hold your head up high, ...</td>\n",
       "      <td>sad</td>\n",
       "      <td>sometim hold head high blink away tear say goo...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67915</th>\n",
       "      <td>Instead of wiping your tears, wipe away the pe...</td>\n",
       "      <td>sad</td>\n",
       "      <td>instead wipe tear wipe away peopl caus</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67915 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text Emotion  \\\n",
       "0                                i didnt feel humiliated     sad   \n",
       "1      i can go from feeling so hopeless to so damned...     sad   \n",
       "2      ive been feeling a little burdened lately wasn...     sad   \n",
       "3      i feel as confused about life as a teenager or...    fear   \n",
       "4      i have been with petronas for years i feel tha...     joy   \n",
       "...                                                  ...     ...   \n",
       "67911  Stop crying over yesterday and start smiling f...     sad   \n",
       "67912  An Eye with Dust ‘n A Heart with Trust Always ...     sad   \n",
       "67913  Tears come from the heart and not from the brain.     sad   \n",
       "67914  Sometimes you have to hold your head up high, ...     sad   \n",
       "67915  Instead of wiping your tears, wipe away the pe...     sad   \n",
       "\n",
       "                                             cleaned_doc  length  \n",
       "0                                      didnt feel humili       3  \n",
       "1      go feel hopeless damn hope around someon care ...       9  \n",
       "2                  ive feel littl burden late wasnt sure       7  \n",
       "3              feel confus life teenag jade year old man       8  \n",
       "4      petrona year feel petrona perform well made hu...       9  \n",
       "...                                                  ...     ...  \n",
       "67911            stop cri yesterday start smile tomorrow       6  \n",
       "67912                   eye dust n heart trust alway cri       7  \n",
       "67913                              tear come heart brain       4  \n",
       "67914  sometim hold head high blink away tear say goo...      10  \n",
       "67915             instead wipe tear wipe away peopl caus       7  \n",
       "\n",
       "[67915 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "-s-Cl5wUxK39"
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CNcdhxMC9h0D",
    "outputId": "3076e409-1bf4-4fc4-b8cb-a1cf9c7e5a9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "FGn13zA-7d4k",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2123/2123 [==============================] - ETA: 0s - loss: 1.0465 - accuracy: 0.5552WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2123/2123 [==============================] - 465s 218ms/step - loss: 1.0465 - accuracy: 0.5552\n",
      "Epoch 2/30\n",
      "2123/2123 [==============================] - ETA: 0s - loss: 0.7991 - accuracy: 0.6854WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2123/2123 [==============================] - 464s 219ms/step - loss: 0.7991 - accuracy: 0.6854\n",
      "Epoch 3/30\n",
      "2123/2123 [==============================] - ETA: 0s - loss: 0.5863 - accuracy: 0.7834WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2123/2123 [==============================] - 459s 216ms/step - loss: 0.5863 - accuracy: 0.7834\n",
      "Epoch 4/30\n",
      "2123/2123 [==============================] - ETA: 0s - loss: 0.4487 - accuracy: 0.8335WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2123/2123 [==============================] - 7283s 3s/step - loss: 0.4487 - accuracy: 0.8335\n",
      "Epoch 5/30\n",
      "2123/2123 [==============================] - ETA: 0s - loss: 0.3610 - accuracy: 0.8618WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2123/2123 [==============================] - 463s 218ms/step - loss: 0.3610 - accuracy: 0.8618\n",
      "Epoch 6/30\n",
      "2123/2123 [==============================] - ETA: 0s - loss: 0.2993 - accuracy: 0.8849WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2123/2123 [==============================] - 454s 214ms/step - loss: 0.2993 - accuracy: 0.8849\n",
      "Epoch 7/30\n",
      "2123/2123 [==============================] - ETA: 0s - loss: 0.2592 - accuracy: 0.8992WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2123/2123 [==============================] - 455s 214ms/step - loss: 0.2592 - accuracy: 0.8992\n",
      "Epoch 8/30\n",
      "2123/2123 [==============================] - ETA: 0s - loss: 0.2303 - accuracy: 0.9108WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2123/2123 [==============================] - 569s 268ms/step - loss: 0.2303 - accuracy: 0.9108\n",
      "Epoch 9/30\n",
      "2123/2123 [==============================] - ETA: 0s - loss: 0.2024 - accuracy: 0.9205WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2123/2123 [==============================] - 458s 216ms/step - loss: 0.2024 - accuracy: 0.9205\n",
      "Epoch 10/30\n",
      "2123/2123 [==============================] - ETA: 0s - loss: 0.1812 - accuracy: 0.9303WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2123/2123 [==============================] - 459s 216ms/step - loss: 0.1812 - accuracy: 0.9303\n",
      "Epoch 11/30\n",
      "2123/2123 [==============================] - ETA: 0s - loss: 0.1610 - accuracy: 0.9373WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2123/2123 [==============================] - 473s 223ms/step - loss: 0.1610 - accuracy: 0.9373\n",
      "Epoch 12/30\n",
      "2123/2123 [==============================] - ETA: 0s - loss: 0.1493 - accuracy: 0.9418WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2123/2123 [==============================] - 460s 216ms/step - loss: 0.1493 - accuracy: 0.9418\n",
      "Epoch 13/30\n",
      "2123/2123 [==============================] - ETA: 0s - loss: 0.1350 - accuracy: 0.9476WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2123/2123 [==============================] - 470s 222ms/step - loss: 0.1350 - accuracy: 0.9476\n",
      "Epoch 14/30\n",
      "2123/2123 [==============================] - ETA: 0s - loss: 0.1205 - accuracy: 0.9535WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2123/2123 [==============================] - 468s 220ms/step - loss: 0.1205 - accuracy: 0.9535\n",
      "Epoch 15/30\n",
      "2123/2123 [==============================] - ETA: 0s - loss: 0.1125 - accuracy: 0.9558WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2123/2123 [==============================] - 523s 247ms/step - loss: 0.1125 - accuracy: 0.9558\n",
      "Epoch 16/30\n",
      "2123/2123 [==============================] - ETA: 0s - loss: 0.1035 - accuracy: 0.9593WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2123/2123 [==============================] - 524s 247ms/step - loss: 0.1035 - accuracy: 0.9593\n",
      "Epoch 17/30\n",
      "2123/2123 [==============================] - ETA: 0s - loss: 0.0943 - accuracy: 0.9630WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2123/2123 [==============================] - 460s 216ms/step - loss: 0.0943 - accuracy: 0.9630\n",
      "Epoch 18/30\n",
      "2123/2123 [==============================] - ETA: 0s - loss: 0.0887 - accuracy: 0.9650WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2123/2123 [==============================] - 461s 217ms/step - loss: 0.0887 - accuracy: 0.9650\n",
      "Epoch 19/30\n",
      "2123/2123 [==============================] - ETA: 0s - loss: 0.0810 - accuracy: 0.9694WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2123/2123 [==============================] - 1132s 533ms/step - loss: 0.0810 - accuracy: 0.9694\n",
      "Epoch 20/30\n",
      "2123/2123 [==============================] - ETA: 0s - loss: 0.0776 - accuracy: 0.9705WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2123/2123 [==============================] - 745s 351ms/step - loss: 0.0776 - accuracy: 0.9705\n",
      "Epoch 21/30\n",
      "2123/2123 [==============================] - ETA: 0s - loss: 0.0730 - accuracy: 0.9727WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2123/2123 [==============================] - 774s 365ms/step - loss: 0.0730 - accuracy: 0.9727\n",
      "Epoch 22/30\n",
      "2123/2123 [==============================] - ETA: 0s - loss: 0.0678 - accuracy: 0.9743WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2123/2123 [==============================] - 797s 375ms/step - loss: 0.0678 - accuracy: 0.9743\n",
      "Epoch 23/30\n",
      "2123/2123 [==============================] - ETA: 0s - loss: 0.0631 - accuracy: 0.9759WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2123/2123 [==============================] - 763s 359ms/step - loss: 0.0631 - accuracy: 0.9759\n",
      "Epoch 24/30\n",
      "2123/2123 [==============================] - ETA: 0s - loss: 0.0625 - accuracy: 0.9768WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2123/2123 [==============================] - 631s 297ms/step - loss: 0.0625 - accuracy: 0.9768\n",
      "Epoch 25/30\n",
      "2123/2123 [==============================] - ETA: 0s - loss: 0.0588 - accuracy: 0.9775WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2123/2123 [==============================] - 541s 255ms/step - loss: 0.0588 - accuracy: 0.9775\n",
      "Epoch 26/30\n",
      "2123/2123 [==============================] - ETA: 0s - loss: 0.0549 - accuracy: 0.9794WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2123/2123 [==============================] - 556s 262ms/step - loss: 0.0549 - accuracy: 0.9794\n",
      "Epoch 27/30\n",
      "2123/2123 [==============================] - ETA: 0s - loss: 0.0520 - accuracy: 0.9805WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2123/2123 [==============================] - 564s 266ms/step - loss: 0.0520 - accuracy: 0.9805\n",
      "Epoch 28/30\n",
      "2123/2123 [==============================] - ETA: 0s - loss: 0.0508 - accuracy: 0.9806WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2123/2123 [==============================] - 2401s 1s/step - loss: 0.0508 - accuracy: 0.9806\n",
      "Epoch 29/30\n",
      "2123/2123 [==============================] - ETA: 0s - loss: 0.0497 - accuracy: 0.9815WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2123/2123 [==============================] - 540s 254ms/step - loss: 0.0497 - accuracy: 0.9815\n",
      "Epoch 30/30\n",
      "2123/2123 [==============================] - ETA: 0s - loss: 0.0490 - accuracy: 0.9822WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "2123/2123 [==============================] - 568s 268ms/step - loss: 0.0490 - accuracy: 0.9822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1efb7288190>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build and compile the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=150, input_length=300))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "callback = EarlyStopping(monitor=\"val_loss\", patience=2, restore_best_weights=True)\n",
    "model.fit(x_train, y_train, epochs=30, batch_size=32, verbose=1, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bnsla\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(lb,open(\"lb.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
